{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0cc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9829ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..') #appends project root to path in order to import project packages since `noteboks_dev` is not on the root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d1074",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e031a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import nmslib\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from heartwood.utils import sparsify, hstack, vstack, stack, RobustEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7caca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NMSLibSklearnWrapper(BaseEstimator):\n",
    "        \n",
    "    def __init__(\n",
    "        self,\n",
    "        #init index params\n",
    "        nmslib_method='hnsw',\n",
    "        nmslib_space='jaccard_sparse', \n",
    "        nmslib_data_type=nmslib.DataType.OBJECT_AS_STRING,\n",
    "        nmslib_space_params = {},\n",
    "        #index creation params\n",
    "        index_time_params = {'M': 30, 'indexThreadQty': 4, 'efConstruction': 100, 'post' : 0},\n",
    "        query_time_params = {'efSearch': 100},        \n",
    "        #\n",
    "        n_neighbors = 30,        \n",
    "        verbose = False,\n",
    "        #x_prep_function\n",
    "        X_prep_function = None\n",
    "    ):\n",
    "        \n",
    "                \n",
    "        self.nmslib_method = nmslib_method\n",
    "        self.nmslib_space=nmslib_space\n",
    "        self.nmslib_data_type=nmslib_data_type\n",
    "        self.nmslib_space_params = nmslib_space_params\n",
    "        #index creation params\n",
    "        self.index_time_params = index_time_params\n",
    "        self.query_time_params = query_time_params\n",
    "        #\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.verbose = verbose\n",
    "        #x_prep_function\n",
    "        self.X_prep_function = X_prep_function\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _preprocess_X(self, X):\n",
    "        '''\n",
    "        encodes sparse rows into str of id of nonzero columns\n",
    "        '''\n",
    "        if not self.X_prep_function is None:\n",
    "            X = self.X_prep_function(X)\n",
    "        \n",
    "        return X\n",
    "        \n",
    "    \n",
    "    def _instantiate_index(self,):\n",
    "        '''\n",
    "        method for instantiating index.\n",
    "        usefull for pickling\n",
    "        '''         \n",
    "        \n",
    "        index = nmslib.init(\n",
    "            method = self.nmslib_method,\n",
    "            space = self.nmslib_space,\n",
    "            data_type = self.nmslib_data_type,\n",
    "            space_params = self.nmslib_space_params\n",
    "        )\n",
    "        \n",
    "        return index\n",
    "        \n",
    "    def fit(self, X, y = None, **kwargs):\n",
    "        '''\n",
    "        instantiates and creates index\n",
    "        '''\n",
    "        #instantiate index\n",
    "        index = self._instantiate_index()\n",
    "        # preprocess X\n",
    "        X_prep = self._preprocess_X(X)        \n",
    "        #add points to index\n",
    "        index.addDataPointBatch(X_prep)\n",
    "        # Create an index        \n",
    "        index.createIndex(self.index_time_params, self.verbose)\n",
    "        #handle None for y (data to save under indexes)\n",
    "        if y is None:\n",
    "            y = np.ones((X.shape[0], 0)) #empty array\n",
    "        # save states\n",
    "        self.index_ = index        \n",
    "        self.y_ = y\n",
    "        self.X_ = X\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y = None, **kwargs):\n",
    "        '''\n",
    "        adds new datapoints to index and y.\n",
    "        estimator needs to be fit prior to calling partial fit,\n",
    "        so first call fit in the first batch of data, then call partial fit \n",
    "        passing the subsequent batches\n",
    "        '''        \n",
    "        #assume index is already instantiated\n",
    "        # preprocess X\n",
    "        X_prep = self._preprocess_X(X)        \n",
    "        #add points to index\n",
    "        self.index_.addDataPointBatch(X_prep)\n",
    "        # Create an index        \n",
    "        self.index_.createIndex(self.index_time_params, self.verbose)\n",
    "        #handle None for y (data to save under indexes)\n",
    "        if y is None:\n",
    "            y = np.ones((X.shape[0], 0)) #empty array\n",
    "        # save states                \n",
    "        self.y_ = vstack([self.y_, y])\n",
    "        self.X_ = vstack([self.X_, X])\n",
    "        return self\n",
    "    \n",
    "    def kneighbors(self, X = None, n_neighbors = None, return_distance = True, query_time_params = None, n_jobs = 4):\n",
    "        '''\n",
    "        query neighbors, if X is None, will return the neighbors of each point in index\n",
    "        '''\n",
    "        if query_time_params is None:\n",
    "            query_time_params = self.query_time_params\n",
    "        if n_neighbors is None:\n",
    "            n_neighbors = self.n_neighbors\n",
    "        if X is None:\n",
    "            X = self.X_\n",
    "        \n",
    "        #preprocess X\n",
    "        X = self._preprocess_X(X)            \n",
    "        \n",
    "        self.index_.setQueryTimeParams(query_time_params)\n",
    "\n",
    "        # Querying                        \n",
    "        start = time.time() \n",
    "        nbrs = self.index_.knnQueryBatch(X, k = n_neighbors, num_threads = n_jobs)\n",
    "        end = time.time() \n",
    "        \n",
    "        if self.verbose:\n",
    "            try:\n",
    "                query_qty = len(X)\n",
    "            except:\n",
    "                query_qty = X.shape[0]\n",
    "            print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' % \n",
    "                  (end-start, float(end-start)/query_qty, n_jobs*float(end-start)/query_qty))\n",
    "        \n",
    "        if return_distance:\n",
    "            distances = [nb[0] for nb in nbrs]\n",
    "            nbrs = [nb[1] for nb in nbrs]\n",
    "            return distances, nbrs\n",
    "        else:\n",
    "            nbrs = [nb[1] for nb in nbrs]\n",
    "            return nbrs\n",
    "                        \n",
    "    def __getstate__(self,):\n",
    "        '''\n",
    "        creates binary file for index and then saves into object attribute to be pickled alongside\n",
    "        other attributes.\n",
    "        '''\n",
    "        #read tempfiles with binaries to save binary str inside object\n",
    "        tempfile_name = fr'.~nmslib_index_{str(int(time.time()*1e7))}'\n",
    "        self.index_.saveIndex(tempfile_name, save_data = True)        \n",
    "        \n",
    "        with open(tempfile_name, 'rb') as f:\n",
    "            fb = f.read()        \n",
    "        with open(tempfile_name+'.dat', 'rb') as f:\n",
    "            fb_dat = f.read()\n",
    "        \n",
    "        #save binary as attribute (index and data)\n",
    "        self.index_ = (fb,fb_dat)\n",
    "        #delete tempfiles\n",
    "        Path(tempfile_name).unlink()\n",
    "        Path(tempfile_name+'.dat').unlink()\n",
    "        return self.__dict__\n",
    "    \n",
    "    def __setstate__(self,d):\n",
    "        '''\n",
    "        sets state during unpickling.\n",
    "        instantiates index and loads binary index\n",
    "        '''\n",
    "        self.__dict__ = d\n",
    "        \n",
    "        #write tempfiles with binaries to load from index.loadIndex\n",
    "        tempfile_name = fr'.~nmslib_index_{str(int(time.time()*1e7))}'        \n",
    "        with open(tempfile_name, 'wb') as f:\n",
    "            f.write(self.index_[0])\n",
    "            \n",
    "        with open(tempfile_name+'.dat', 'wb') as f:\n",
    "            f.write(self.index_[1])\n",
    "        \n",
    "        index = self._instantiate_index()\n",
    "        index.loadIndex(tempfile_name, load_data = True)\n",
    "        #sets self.index_\n",
    "        self.index_ = index\n",
    "        #delete tempfile\n",
    "        Path(tempfile_name).unlink()        \n",
    "        Path(tempfile_name+'.dat').unlink()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ef1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _preprocess_sparse_to_idx_str(X):\n",
    "    '''\n",
    "    encodes sparse rows into str of id of nonzero columns\n",
    "    '''\n",
    "    #ensure is sparse\n",
    "    X = sparse.csr_matrix(X)\n",
    "    indptr = X.indptr\n",
    "    cols = X.tocoo().col.astype(str)\n",
    "    id_strs = [*(' '.join(cols[slice(*indptr[i:i+2])]) for i in range(len(indptr)-1))]\n",
    "    return id_strs\n",
    "\n",
    "\n",
    "class FastJaccardNN(NMSLibSklearnWrapper):\n",
    "        \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_neighbors = 30,\n",
    "        index_time_params = {'M': 30, 'indexThreadQty': 4, 'efConstruction': 100, 'post' : 0},\n",
    "        query_time_params = {'efSearch': 100},        \n",
    "        verbose = False,\n",
    "    ):\n",
    "                        \n",
    "        super().__init__(\n",
    "            #jaccard init params\n",
    "            nmslib_method='hnsw',\n",
    "            nmslib_space='jaccard_sparse', \n",
    "            nmslib_data_type=nmslib.DataType.OBJECT_AS_STRING,\n",
    "            nmslib_space_params = {},\n",
    "            #other params\n",
    "            X_prep_function = _preprocess_sparse_to_idx_str,\n",
    "            n_neighbors = n_neighbors,\n",
    "            index_time_params = index_time_params,\n",
    "            query_time_params = query_time_params,\n",
    "            verbose = verbose,                    \n",
    "        )\n",
    "        return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ddc408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "import joblib\n",
    "X = joblib.load('terminal_node_embs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67a0b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN time total=3.225677 (sec), per query=0.000161 (sec), per query adjusted for thread number=0.001290 (sec)\n"
     ]
    }
   ],
   "source": [
    "jcd = FastJaccardNN(verbose = True).fit(tree_embeddings)\n",
    "jcd.partial_fit(X)\n",
    "results = jcd.kneighbors(n_jobs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e07438f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN time total=4.605462 (sec), per query=0.000154 (sec), per query adjusted for thread number=0.001228 (sec)\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(jcd,'jcd.sav')\n",
    "jcd = joblib.load('jcd.sav')\n",
    "#appends to index\n",
    "jcd.partial_fit(X)\n",
    "results = jcd.kneighbors(n_jobs = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0fe84",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147b4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted index.ipynb.\n",
      "Converted kernel.ipynb.\n",
      "Converted neighbors.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1b0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
