{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nbdev import session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..') #appends project root to path in order to import project packages since `noteboks_dev` is not on the root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import reduce\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import normalize, OneHotEncoder, OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sknetwork.clustering import KMeans, Louvain, PropagationClustering\n",
    "\n",
    "from nmslearn.neighbors import FastJaccardNN, FastKLDivNN, FastL2NN\n",
    "\n",
    "from heartwood.utils import hstack, RobustEncoder, sparse_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session of variables to testing sessions\n",
    "n_features = 7\n",
    "cardinality_per_feature = 1000\n",
    "n_classes = 5\n",
    "n_reg_dims = 2\n",
    "\n",
    "\n",
    "X = np.random.randint(0,cardinality_per_feature,(1000,n_features))\n",
    "\n",
    "y_class = np.random.randint(0,n_classes, 1000)\n",
    "y_reg = np.random.randn(1000,n_reg_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))\n",
    "\n",
    "def make_bimodal_assymetric_regression(\n",
    "    n_samples=100000,\n",
    "    bimodal_factor_weight = 2,\n",
    "    n_features=15,\n",
    "    n_informative=6,\n",
    "    n_targets=2,\n",
    "    bias=500,\n",
    "    effective_rank=None,\n",
    "    tail_strength=10,\n",
    "    noise=150,\n",
    "    shuffle=True,\n",
    "    coef=False,\n",
    "    random_state=None\n",
    "):\n",
    "    \n",
    "    X,y = make_regression(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative,\n",
    "        n_targets=n_targets,\n",
    "        bias=bias,\n",
    "        effective_rank=effective_rank,\n",
    "        tail_strength=tail_strength,\n",
    "        noise=noise,\n",
    "        shuffle=shuffle,\n",
    "        coef=coef,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "\n",
    "    #make one of X[1] feature mode weightening    \n",
    "    bimodal_factors = (sigmoid(bimodal_factor_weight*X[:,-1]) > np.random.random(size = X.shape[0])).astype(int)\n",
    "    bimodal_factors[bimodal_factors == 0] = -1\n",
    "    bimodal_factors = bimodal_factors.reshape(-1,1)\n",
    "\n",
    "    y = bimodal_factors*y\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_regression, make_blobs\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples = 100_000,\n",
    "    n_features = 3,\n",
    "    n_informative = 3,\n",
    "    n_redundant = 0,\n",
    "    #bias = 10,\n",
    "    #noise = 10,\n",
    "    n_classes = 3,\n",
    "    n_clusters_per_class = 2,\n",
    "    hypercube = True,\n",
    ")\n",
    "\n",
    "\n",
    "blobs, labels = make_blobs(n_samples = 10_000,cluster_std = 3, n_features = 4)\n",
    "#sns.scatterplot(*blobs.T, hue = labels)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='iframe'\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df.columns = [f'X{i}' for i in range(X.shape[-1])]\n",
    "df['y'] = y.astype(str)\n",
    "\n",
    "fig = px.scatter_3d(df, x='X0', y='X1', z='X2',\n",
    "              color='y')\n",
    "#fig.show()\n",
    "\n",
    "#plt.cls()\n",
    "#sns.scatterplot(*X.T[:2], hue = y)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sparsify(*arrs):\n",
    "    '''\n",
    "    makes input arrs sparse\n",
    "    '''\n",
    "    arrs = list(arrs)\n",
    "    for i in range(len(arrs)):        \n",
    "        if not sparse.issparse(arrs[i]):\n",
    "            arrs[i] = sparse.csr_matrix(arrs[i])\n",
    "    \n",
    "    return arrs\n",
    "\n",
    "def _robust_stack(blocks, stack_method = 'stack', **kwargs):\n",
    "    \n",
    "    if any(sparse.issparse(i) for i in blocks):\n",
    "        stacked = getattr(sparse, stack_method)(blocks, **kwargs)\n",
    "    else:\n",
    "        stacked = getattr(np, stack_method)(blocks, **kwargs)\n",
    "    return stacked\n",
    "\n",
    "def hstack(blocks, **kwargs):\n",
    "    return _robust_stack(blocks, stack_method = 'hstack', **kwargs)\n",
    "\n",
    "def vstack(blocks, **kwargs):\n",
    "    return _robust_stack(blocks, stack_method = 'vstack', **kwargs)\n",
    "\n",
    "def stack(blocks, **kwargs):\n",
    "    return _robust_stack(blocks, stack_method = 'stack', **kwargs)\n",
    "\n",
    "\n",
    "class RobustEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,):            \n",
    "        '''\n",
    "        A robust one hot encoder. Always return the same amount of nonzero value sin each transformed row.\n",
    "        Has columns for unknown values\n",
    "        '''\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y = None, **kwawrgs):        \n",
    "        self.ordinalencoder_ = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1).fit(X)\n",
    "        \n",
    "        X = self.ordinalencoder_.transform(X)\n",
    "        \n",
    "        categories = [np.arange(-1, len(cats)) for cats in self.ordinalencoder_.categories_]\n",
    "        self.onehotencoder_ = OneHotEncoder(categories = categories).fit(X)        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **kwargs):\n",
    "        X = self.ordinalencoder_.transform(X)\n",
    "        return self.onehotencoder_.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class PrefitEstimator(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, prefit_estimator):\n",
    "        self.prefit_estimator = prefit_estimator\n",
    "        self.is_fitted_ = True\n",
    "        return\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        '''\n",
    "        gets the attributes from prefit_estimator, except if the attribute (or method)\n",
    "        is \"fit\".\n",
    "        \n",
    "        if the \"transform\" or \"predict\" method is called, it'll return self.prefit_estimator's method\n",
    "        '''\n",
    "        if attr == 'fit':\n",
    "            return self.fit        \n",
    "        elif attr == 'fit_transform':\n",
    "            return self.fit_transform\n",
    "        elif attr == 'fit_predict':\n",
    "            return self.fit_predict            \n",
    "        else:\n",
    "            return getattr(self.prefit_estimator, attr)\n",
    "    \n",
    "    def fit(self, X, y = None, **kwargs):\n",
    "        '''\n",
    "        the fit method does nothing (since prefit_estimator is already fitted) and returns self.\n",
    "        '''\n",
    "        return self    \n",
    "    \n",
    "    def fit_transform(self, X, y = None, **kwargs):\n",
    "        return self.transform(X) #will get \"transform\" method from self.prefit_estimator\n",
    "    \n",
    "    def fit_predict(self, X, y = None, **kwargs):\n",
    "        return self.predict(X) #will get \"predict\" method from self.prefit_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTreePipeline():\n",
    "    '''\n",
    "    Extends sklearn Pipeline with tree methods such as `apply` and `decistion_path`\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "class CustomRandomForest():\n",
    "    '''\n",
    "    extends RandomForests to work with CustomTreePipeline\n",
    "    '''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestNeighbors(BaseEstimator):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        forest_estimator,\n",
    "        n_neighbors = 30,\n",
    "        radius = .5,\n",
    "        n_jobs = -1,\n",
    "        prefit_forest_estimator = False,\n",
    "    ):\n",
    "        '''\n",
    "        Kneighbors search based on terminal node co-ocurrence.\n",
    "        Trees can be grown adaptatively (supervised tree ensemble) or randomly (unsupervised tree ensemble)        \n",
    "        '''\n",
    "        self.forest_estimator = forest_estimator\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.radius = radius\n",
    "        self.n_jobs = n_jobs\n",
    "        self.prefit_forest_estimator = prefit_forest_estimator\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y = None, **kwargs):\n",
    "        '''\n",
    "        fits forest_estimator if prefir_forest_estimator is set to False. Then, fits neighbors search index\n",
    "        '''\n",
    "        \n",
    "        if not self.prefit_forest_estimator:\n",
    "            self.forest_estimator.fit(X = X, y = y, **kwargs)\n",
    "        else:\n",
    "            pass\n",
    "                        \n",
    "        #get terminal node indexes\n",
    "        node_indexes = self.forest_estimator.apply(X)        \n",
    "        #create node encoding pipeline\n",
    "        index_encoder = make_pipeline(OrdinalEncoder(), OneHotEncoder())\n",
    "        index_encoder.fit(node_indexes)\n",
    "        #create node->point mapper\n",
    "        node_point_mapper = self._create_node_point_mapper(node_indexes, index_encoder)\n",
    "        point_node_mapping = index_encoder.fit_transform(node_indexes)\n",
    "        #save states        \n",
    "        self.point_node_mapping_ = point_node_mapping\n",
    "        self.index_encoder_ = index_encoder\n",
    "        return self\n",
    "    \n",
    "    def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n",
    "        \n",
    "        if X is None:\n",
    "            points = self.point_node_mapping_\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            \n",
    "    \n",
    "    def _create_node_point_mapper(self, node_indexes, index_encoder):\n",
    "        '''\n",
    "        creates terminal_node->points mapper in order to retrieve points based on terminal nodes\n",
    "        '''\n",
    "        point_node_mapping = index_encoder.transform(node_indexes)\n",
    "        M = point_node_mapping.T.tocsr()\n",
    "        mapper = np.array(np.split(M.indices, M.indptr)[1:-1])\n",
    "        return mapper\n",
    "\n",
    "    def _correct_node_indexes(self, node_indexes, index_encoder):    \n",
    "        '''\n",
    "        correct node indexes to reflect actual positional indexing of nodes in the forest\n",
    "        '''\n",
    "\n",
    "        node_indexes = index_encoder[0].transform(node_indexes)    \n",
    "        sum_indexes = np.roll((node_indexes.max(0) + 1).reshape(1,-1).cumsum(), 1, )\n",
    "        sum_indexes[0] = 0\n",
    "        sum_indexes = sum_indexes.astype(int)    \n",
    "        corrected_indexes = (node_indexes + sum_indexes).astype(int)\n",
    "        return corrected_indexes\n",
    "\n",
    "    def _postprocess_node_points(self, points, n_neighbors = 30, ):\n",
    "        '''\n",
    "        postprocess queried points\n",
    "        '''    \n",
    "        dist = []\n",
    "        idx = []\n",
    "        n_terminal_nodes = points.shape[1]\n",
    "        #points = mapper[corrected_indexes]\n",
    "        for i in range(len(points)):\n",
    "            idx_, count_ = np.unique(np.concatenate(points[i]), return_counts = True)\n",
    "            argsort = np.argsort(count_)[::-1][:n_neighbors]\n",
    "            dist.append(count_[argsort].reshape(1,-1)/n_terminal_nodes)\n",
    "            idx.append(idx_[argsort].reshape(1,-1))\n",
    "\n",
    "        dist, idx = np.vstack(dist), np.vstack(idx)\n",
    "        return dist, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = make_pipeline(OrdinalEncoder(), OneHotEncoder())\n",
    "point_node_mapping = encoder.fit_transform(mxfc.estimators[1].apply(X))\n",
    "node_indexes = encoder[0].transform(mxfc.estimators[1].apply(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning:\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "238409"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = point_node_mapping.T.tocsr()\n",
    "\n",
    "mapper = np.array(np.split(M.indices, M.indptr)[1:-1])\n",
    "len(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.4 µs ± 516 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "24.7 µs ± 879 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%timeit np.bincount(np.concatenate(mapper[[1,2,310]]))#.ravel()\n",
    "%timeit np.unique(np.concatenate(mapper[[1,2,310]]), return_counts = True)#.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [01:25<00:00, 1166.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "n_neighbors = 100\n",
    "\n",
    "\n",
    "sum_indexes = np.roll((node_indexes.max(0) + 1).reshape(1,-1).cumsum(), 1, )\n",
    "sum_indexes[0] = 0\n",
    "sum_indexes = sum_indexes.astype(int)\n",
    "\n",
    "node_indexes = encoder[0].transform(mxfc.estimators[1].apply(X))\n",
    "query_node_indexes = node_indexes\n",
    "corrected_indexes = (query_node_indexes + sum_indexes).astype(int)\n",
    "\n",
    "n_terminal_nodes = corrected_indexes.shape[1]\n",
    "\n",
    "\n",
    "dist = []\n",
    "idx = []\n",
    "points = mapper[corrected_indexes]\n",
    "for i in tqdm(range(len(corrected_indexes))):    \n",
    "    idx_, count_ = np.unique(np.concatenate(points[i]), return_counts = True)\n",
    "    argsort = np.argsort(count_)[::-1][:n_neighbors]\n",
    "    dist.append(count_[argsort]/n_terminal_nodes)\n",
    "    idx.append(idx_[argsort])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and save node_ordinal_encoder\n",
    "def create_node_point_mapper(node_indexes, index_encoder):\n",
    "    '''\n",
    "    creates terminal_node->points mapper in order to retrieve points based on terminal nodes\n",
    "    '''\n",
    "    point_node_mapping = index_encoder.transform(node_indexes)\n",
    "    M = point_node_mapping.T.tocsr()\n",
    "    mapper = np.array(np.split(M.indices, M.indptr)[1:-1])\n",
    "    return mapper\n",
    "\n",
    "def correct_node_indexes(node_indexes, index_encoder):    \n",
    "    '''\n",
    "    correct node indexes to reflect actual positional indexing of nodes in the forest\n",
    "    '''\n",
    "    \n",
    "    node_indexes = index_encoder[0].transform(node_indexes)    \n",
    "    sum_indexes = np.roll((node_indexes.max(0) + 1).reshape(1,-1).cumsum(), 1, )\n",
    "    sum_indexes[0] = 0\n",
    "    sum_indexes = sum_indexes.astype(int)    \n",
    "    corrected_indexes = (node_indexes + sum_indexes).astype(int)\n",
    "    return corrected_indexes\n",
    "\n",
    "def postprocess_node_points(points, n_neighbors = 30, ):\n",
    "    '''\n",
    "    postprocess queried points\n",
    "    '''    \n",
    "    dist = []\n",
    "    idx = []\n",
    "    n_terminal_nodes = points.shape[1]\n",
    "    #points = mapper[corrected_indexes]\n",
    "    for i in range(len(points)):\n",
    "        idx_, count_ = np.unique(np.concatenate(points[i]), return_counts = True)\n",
    "        argsort = np.argsort(count_)[::-1][:n_neighbors]\n",
    "        dist.append(count_[argsort].reshape(1,-1)/n_terminal_nodes)\n",
    "        idx.append(idx_[argsort].reshape(1,-1))\n",
    "    \n",
    "    dist, idx = np.vstack(dist), np.vstack(idx)\n",
    "    return dist, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\ipykernel_launcher.py:8: VisibleDeprecationWarning:\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexes = mxfc.estimators[1].apply(X)\n",
    "#correct_node_indexes(indexes, encoder)\n",
    "encoder.fit(indexes)\n",
    "mapper = create_node_point_mapper(indexes, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_indexes = correct_node_indexes(indexes, encoder)\n",
    "#dist,idx = query_points(mapper, corrected_indexes, n_neighbors = 30, )\n",
    "#encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time Parallel computing 34.97 s\n",
      "\n",
      "\n",
      "Elapsed time single threaded 83.25 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from joblib import effective_n_jobs\n",
    "\n",
    "n_jobs = effective_n_jobs(n_jobs)\n",
    "\n",
    "tic = time.time()\n",
    "results = Parallel(n_jobs=-1)(delayed(postprocess_node_points)(mapper[i], n_neighbors = 100) for i in np.split(corrected_indexes, n_jobs))\n",
    "toc = time.time()\n",
    "print('\\nElapsed time Parallel computing {:.2f} s\\n'\n",
    "      .format(toc - tic))\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "results = postprocess_node_points(mapper[corrected_indexes], n_neighbors = 100)\n",
    "toc = time.time()\n",
    "print('\\nElapsed time single threaded {:.2f} s\\n'\n",
    "      .format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  8411, 42888, ..., 36754, 41879, 51525],\n",
       "       [    1, 79376, 82944, ..., 25049, 95935, 68841],\n",
       "       [    2, 77515, 90397, ..., 22734, 90585, 61919],\n",
       "       ...,\n",
       "       [99997, 61165, 36725, ...,  7316, 61545, 73973],\n",
       "       [99998, 71733, 73635, ..., 19548, 18806, 52823],\n",
       "       [99999, 38335, 58754, ..., 30466, 67099, 74343]], dtype=int32)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest space partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ForestBipartiteGraphTransformer(BaseEstimator):\n",
    "    #fit models and graph embeddings on terminal node space\n",
    "    #save louvain terminal node embeddings for inference\n",
    "    #transform method will yield louvain embeddings of the point\n",
    "    #create get_label method\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        forest_estimator,\n",
    "        embedding_method = 'louvain',        \n",
    "        alpha = 1.0,\n",
    "        return_embeddings_as_sparse = True,\n",
    "        **embedding_kws        \n",
    "    ):\n",
    "        '''\n",
    "        a heterogeneous ensemble of forests with bipartitie node-point graph embedding functionality\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        forest_estimator: forest estimator\n",
    "            Forest estimator. Can be sklearns or any other implementation containing  the `apply` method\n",
    "                \n",
    "        \n",
    "        embedding_method: {'louvain', 'kmeans', 'propagation'}\n",
    "            embedding method from sknetwork. Embeddings are calculaated as the normalized linear combination of memberships of terminal nodes.\n",
    "            for more information about the methods please refer to https://scikit-network.readthedocs.io/en/latest/reference/clustering.html\n",
    "        \n",
    "        alpha: float\n",
    "            concentration parameter. Will concentrate or distribute the embedding dimensions, such that embeddings = normalize(normalize(embeddings)**alpha)\n",
    "        \n",
    "        return_embeddings_as_sparse: bool\n",
    "            whether to return embeddings results as a sparse matrix or a dense one\n",
    "        \n",
    "        embedding_kws: key word arguments\n",
    "            key word araguments passed to the constructor of the clustering object trained to build the embeddings. for more details please refer to https://scikit-network.readthedocs.io/en/latest/reference/clustering.html\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ForestBipartiteGraphTransformer object\n",
    "        \n",
    "        '''\n",
    "        self.forest_estimator = forest_estimator\n",
    "        self.embedding_method = embedding_method\n",
    "        self.return_embeddings_as_sparse = return_embeddings_as_sparse\n",
    "        self.alpha = alpha\n",
    "        self.embedding_kws = embedding_kws\n",
    "        return\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        '''\n",
    "        returns self.forest_estimator attribute if not found in class definition\n",
    "        '''\n",
    "        return getattr(self.forest_estimator, attr)\n",
    "    \n",
    "    def fit(self, X, y = None, **kwargs):\n",
    "        '''\n",
    "        fits the estimator in supervised or unsupervised manner, according to `forest_estimator` type.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X: array like\n",
    "            input independent variables\n",
    "        \n",
    "        y: array like\n",
    "            output target variables\n",
    "        \n",
    "        **kwargs:\n",
    "            keyword arguments passed in self.forest_estimator.fit(X = X, y = y, **kwargs)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        ForestBipartiteGraphTransformer fitted object\n",
    "        \n",
    "        '''\n",
    "        #fit estimator\n",
    "        self.forest_estimator.fit(X = X, y = y, **kwargs)\n",
    "        # gets terminal nodes\n",
    "        terminal_nodes = self.apply(X)        \n",
    "        #fit one hot encoders of the nodes        \n",
    "        self.one_hot_node_embeddings_encoders_ = OneHotEncoder().fit(terminal_nodes)\n",
    "        #fits emedder\n",
    "        self.graph_embedder_ = self._fit_embeddings(X, **kwargs)\n",
    "        return self\n",
    "        \n",
    "    def apply(self, X, **kwargs):\n",
    "        '''\n",
    "        applies method \"apply\" of `forest_estimator` ensuring shape compatibility\n",
    "        '''\n",
    "        X = self.forest_estimator.apply(X, **kwargs)\n",
    "        #handle boosting case\n",
    "        if len(X.shape) > 2:\n",
    "            X = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "        return X\n",
    "    \n",
    "    def node_biadjecency_matrix(self, X):\n",
    "        \n",
    "        terminal_nodes = self.apply(X)        \n",
    "        #gets biadjecency matrix\n",
    "        biadjecency_matrix = self.one_hot_node_embeddings_encoders_.transform(terminal_nodes)\n",
    "        biadjecency_matrix = sparse.csr_matrix(biadjecency_matrix)\n",
    "        return biadjecency_matrix\n",
    "    \n",
    "    def fit_embeddings(self, X, embedding_method = None, **kwargs):\n",
    "        '''\n",
    "        fits only the embedding object. Will use the forest estimator that was fitted in the `fit` method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X: array like\n",
    "            input matrix\n",
    "        \n",
    "        embedding_method: {\"kmeans\", \"propagation\", \"louvain\"}\n",
    "            Clustering method for the terminal nodes. Please refer to https://scikit-network.readthedocs.io/en/latest/reference/clustering.html .\n",
    "            if None is passed, will use `embedding_method` passed in the constructor.\n",
    "        \n",
    "        **kwargs:\n",
    "            keyword arguments passed to the embedding object constructor. Please refer to https://scikit-network.readthedocs.io/en/latest/reference/clustering.html .\n",
    "            \n",
    "            \n",
    "        '''                \n",
    "        self.graph_embedder_ = self._fit_embeddings(X, embedding_method, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def _fit_embeddings(self, X, embedding_method = None, **kwargs):\n",
    "        \n",
    "        '''\n",
    "        fits embedder and returns fitted object\n",
    "        '''\n",
    "                        \n",
    "        if not kwargs:\n",
    "            kwargs = self.embedding_kws\n",
    "            \n",
    "        if embedding_method is None:\n",
    "            embedding_method = self.embedding_method\n",
    "        \n",
    "        if embedding_method == 'louvain':\n",
    "            method = Louvain(**kwargs)\n",
    "        \n",
    "        elif embedding_method == 'kmeans':\n",
    "            method = KMeans(**kwargs)\n",
    "        \n",
    "        elif embedding_method == 'propagation':\n",
    "            method = PropagationClustering(**kwargs)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'Suported methods are: [\"louvain\",\"propagation\", \"kmeans\"], {embedding_method} was passed.')\n",
    "        \n",
    "        G = self.node_biadjecency_matrix(X)\n",
    "        graph_embedder = method.fit(G)\n",
    "        return graph_embedder\n",
    "        \n",
    "        \n",
    "    def transform(self, X, alpha = None, return_embeddings_as_sparse = None):\n",
    "        '''\n",
    "        Maps X from feature space to embedding space. Embedings are a normalized linear combination of the cluster memberships of the terminal of each point in the ensemble of trees.\n",
    "        It can be interpreted as a Fuzzy clustering index, in the sense that points in between clusters will have their membership shared accross their neighbour clusters.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array like\n",
    "            Input data.\n",
    "        \n",
    "        alpha: float\n",
    "            concentration parameter. Will concentrate or distribute the embedding dimensions, such that embeddings = normalize(normalize(embeddings)**alpha).\n",
    "            if None is passed, will use alpha value passed in the constructor.\n",
    "        \n",
    "        return_embeddings_as_sparse: bool\n",
    "            whether to return embeddings results as a sparse matrix or a dense one.\n",
    "            if None is passed, will use return_embeddings_as_sparse value passed in the constructor.\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        Embeddings: Sparse or dense array\n",
    "             \n",
    "             Mapping of the input in the embedding space        \n",
    "        \n",
    "        '''\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "            \n",
    "        if return_embeddings_as_sparse is None:\n",
    "            return_embeddings_as_sparse = self.return_embeddings_as_sparse\n",
    "            \n",
    "        X = self.node_biadjecency_matrix(X)\n",
    "        terminal_node_embs = sparse.csr_matrix(self.graph_embedder_.membership_col_)\n",
    "                        \n",
    "        #normalization of the normalized exponentialized embeddings\n",
    "        embs = normalize(sparse_dot_product(X, terminal_node_embs, terminal_node_embs.shape[-1]), 'l1')\n",
    "        if alpha != 1:\n",
    "            embs.data  = embs.data**alpha\n",
    "            embs = normalize(embs, 'l1')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if return_embeddings_as_sparse:\n",
    "            embs = sparse.csr_matrix(embs)\n",
    "        else:\n",
    "            if sparse.issparse(embs):\n",
    "                embs = embs.A\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return embs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MixedForestTransformer(ForestBipartiteGraphTransformer):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators,        \n",
    "        estimators_weights = None,\n",
    "        fully_supervised = True,\n",
    "        use_already_fitted = False,\n",
    "        biadjecency_weights = 'uniform',\n",
    "        stack_outputs = True,\n",
    "        #embeddings kws\n",
    "        embedding_method = 'louvain',\n",
    "        alpha = 1.0,\n",
    "        return_embeddings_as_sparse = True,\n",
    "        **embedding_kws\n",
    "    ):\n",
    "        '''\n",
    "        a heterogeneous ensemble of forests with bipartitie node-point graph embedding functionality\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        estimators: List of forest estimators\n",
    "            list of estimators to build heterogeneous ensemble\n",
    "        \n",
    "        estimators_weights: array like or None\n",
    "            array like of weights of each passed estimator. If None, will assume not weights. beware that for graph embeddings,\n",
    "            forests with more estimators will have higher weights since there will be more terminal nodes and thus more edges in the graph.\n",
    "            To make the total wieght of edges uniform in the bipartite graph, set biadjecency_weights as \"uniform\"\n",
    "        \n",
    "        fully_supervised: bool\n",
    "            whether all forests are supervised (takes the same y as a parameter) or mixed (some may be unsupervised, like RandomTreeEmeddings)\n",
    "        \n",
    "        use_laready_fitted: bool\n",
    "            if True, will skip fitting those passed estiamtors that are already fitted. Usefull for building embeddings for ensemble of heterogeneous output (classifier + regressor).\n",
    "            Note that the input must be the same for all estimators or the estimator may induce incosistent results.\n",
    "            \n",
    "        \n",
    "        biadjecency_weights: \"n_estimators\", \"weighted\" or \"uniform\"\n",
    "            how to weight edges in the resulting node-point bipartite graph. \n",
    "            if \"n_estimators\", forests with more estimators will yield graphs with greater sum of edge weights (more edges in general)\n",
    "            if \"weighted\", will uniformize the total graph edges sum and then apply passed wieghts in estimator_weights for each graph\n",
    "            if \"uniform\", will uniformize (make the sum of edge wieghts uniform) accross all graphs            \n",
    "        \n",
    "        stack_outputs: bool\n",
    "            whether to stack the outputs after transformations. i.e. return a list of matrices or a single stacked matrix.\n",
    "        \n",
    "        embedding_method: {'louvain', 'kmeans', 'propagation'}\n",
    "            embedding method from sknetwork. Embeddings are calculaated as the normalized linear combination of memberships of terminal nodes.\n",
    "            for more information about the methods please refer to https://scikit-network.readthedocs.io/en/latest/reference/clustering.html\n",
    "        \n",
    "        alpha: float\n",
    "            concentration parameter. Will concentrate or distribute the embedding dimensions, such that embeddings = normalize(normalize(embeddings)**alpha)\n",
    "        \n",
    "        return_embeddings_as_sparse: bool\n",
    "            whether to return embeddings results as a sparse matrix or a dense one\n",
    "        \n",
    "        embedding_kws: key word arguments\n",
    "            key word araguments passed to the constructor of the clustering object trained to build the embeddings. for more details please refer to https://scikit-network.readthedocs.io/en/latest/reference/clustering.html\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        MixedForestTransformer object\n",
    "        \n",
    "        '''\n",
    "        self.estimators = estimators        \n",
    "        self.estimators_weights = estimators_weights\n",
    "        self.fully_supervised = fully_supervised\n",
    "        self.use_already_fitted = use_already_fitted\n",
    "        self.biadjecency_weights = biadjecency_weights\n",
    "        self.stack_outputs = stack_outputs\n",
    "        #embeddings args\n",
    "        self.embedding_kws = embedding_kws\n",
    "        self.embedding_method = embedding_method\n",
    "        self.alpha = alpha\n",
    "        self.return_embeddings_as_sparse = return_embeddings_as_sparse\n",
    "        return\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        return [getattr(i, attr) for i in self.estimators]\n",
    "        \n",
    "    def _iter_apply(self, method, *args, **kwargs):\n",
    "        \n",
    "        result = []\n",
    "        for estim in self.estimators:\n",
    "            result.append(getattr(estim, method)(*args, **kwargs))\n",
    "        return result\n",
    "            \n",
    "    def apply(self, X, stack = None, **kwargs):\n",
    "        \n",
    "        result = self._iter_apply(method = 'apply', X = X)\n",
    "        \n",
    "        if stack is None:\n",
    "            stack = self.stack_outputs\n",
    "        #handle boosting case where returned array has 3 dims\n",
    "        for arr in result:            \n",
    "            if len(arr.shape) >= 3:\n",
    "                arr = arr.reshape(arr.shape[0], arr.shape[1]*arr.shape[2])                                    \n",
    "            \n",
    "        if stack:\n",
    "            result = hstack(result)\n",
    "        return result    \n",
    "    \n",
    "    def decision_path(self, X, stack = None, **kwargs):\n",
    "        result = self._iter_apply(method = 'decision_path', X = X)        \n",
    "        \n",
    "        if stack is None:\n",
    "            stack = self.stack_outputs\n",
    "        \n",
    "        if stack:\n",
    "            result0 = sparse.csr_matrix(hstack([i[0] for i in result]))\n",
    "            result1 = hstack([i[1] for i in result])\n",
    "        else:\n",
    "            result0,result1 = result\n",
    "        \n",
    "        return result0, result1\n",
    "    \n",
    "    def node_biadjecency_matrix(self, X, use_weights = None, stack = None):\n",
    "        \n",
    "        '''\n",
    "        use_weights can be \"n_estimators\", \"weighted\" or \"uniform\"\n",
    "        unweighted returns biadjecency matrix filled with ones or zeros\n",
    "        uniform makes the total sum of edge weights from all estimators the same\n",
    "        wieghted \n",
    "        '''\n",
    "        \n",
    "        if use_weights is None:\n",
    "            use_weights = self.biadjecency_weights\n",
    "        if stack is None:\n",
    "            stack = self.stack_outputs\n",
    "        \n",
    "        #invert natural weights to make the sum of edges in each biadjacency uniform accross all estimators\n",
    "        natural_weights = np.array([i.n_estimators for i in self.estimators])\n",
    "        natural_weights = natural_weights/natural_weights.sum()            \n",
    "        \n",
    "        uniform_weights = (1/natural_weights)\n",
    "        uniform_weights = uniform_weights/uniform_weights.sum()\n",
    "        \n",
    "        if use_weights == \"uniform\":\n",
    "            weights = uniform_weights\n",
    "        elif use_weights == \"weighted\":\n",
    "            weights = uniform_weights*self.estimators_weights_\n",
    "        elif use_weights == \"n_estimators\":\n",
    "            weights = np.ones((len(self.estimators_weights_),))\n",
    "        else:\n",
    "            raise ValueError(f'use_weights should be one of [\"uniform\", \"weighted\", \"n_estimators\", None], got {use_weights}')\n",
    "                            \n",
    "        terminal_nodes = self.apply(X, stack=False)\n",
    "        biadjs = []\n",
    "        for i in range(len(terminal_nodes)):            \n",
    "            biadj_i = self.one_hot_node_embeddings_encoders_[i].transform(terminal_nodes[i])\n",
    "            #scale and append            \n",
    "            biadjs.append(sparse.csr_matrix((biadj_i*weights[i])))\n",
    "        \n",
    "        if stack:\n",
    "            biadjs = hstack(biadjs)\n",
    "            biadjs = sparse.csr_matrix(biadjs)\n",
    "        \n",
    "        return biadjs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#export   \n",
    "class HeterogeneousMixedForest(MixedForestTransformer):\n",
    "    \n",
    "    def fit(self, X, y = None, sample_weight = None):                        \n",
    "                    \n",
    "        #get \"natural\" weights of estimators\n",
    "        natural_weights = np.array([i.n_estimators for i in self.estimators])\n",
    "        natural_weights = natural_weights/natural_weights.sum()            \n",
    "        #set estimator weights\n",
    "        if self.estimators_weights is None:\n",
    "            weights = natural_weights            \n",
    "        else:\n",
    "            if len(self.estimators_weights) != len(self.estimators):\n",
    "                raise ValueError(f'Shape mismatch between estimators and weights ({len(self.estimators)} != {len(self.estimators_weights)})')            \n",
    "            weights = np.array(self.estimators_weights)\n",
    "            weights = weights/weights.sum()\n",
    "                                                            \n",
    "        \n",
    "        self.natural_weights_ = natural_weights\n",
    "        self.estimators_weights_ = weights\n",
    "        self.classes_ = classes\n",
    "        self.multilabel_ = multilabel\n",
    "        self.output_dim_ = output_dim\n",
    "        \n",
    "        #fit one hot encoders of the nodes\n",
    "        terminal_nodes = super().apply(X, stack = False)\n",
    "        self.one_hot_node_embeddings_encoders_ = [OneHotEncoder().fit(xi) for xi in terminal_nodes]        \n",
    "        #fit louvain embeddings\n",
    "        self.fit_embeddings(X, embedding_method = self.embedding_method,)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MixedForestRegressor(MixedForestTransformer):\n",
    "    \n",
    "    def fit(self, X, y = None, sample_weight = None):\n",
    "                \n",
    "        #check if multidim output\n",
    "        if len(y.shape) > 1:\n",
    "            output_dim = y.shape[-1]\n",
    "        else:\n",
    "            output_dim = 1\n",
    "                        \n",
    "        #get \"natural\" weights of estimators\n",
    "        natural_weights = np.array([i.n_estimators for i in self.estimators])\n",
    "        natural_weights = natural_weights/natural_weights.sum()            \n",
    "        #set estimator weights\n",
    "        if self.estimators_weights is None:\n",
    "            weights = natural_weights            \n",
    "        else:\n",
    "            if len(self.estimators_weights) != len(self.estimators):\n",
    "                raise ValueError(f'Shape mismatch between estimators and weights ({len(self.estimators)} != {len(self.estimators_weights)})')                                    \n",
    "            weights = np.array(self.estimators_weights)\n",
    "            weights = weights/weights.sum()\n",
    "        \n",
    "        #fit estimators if needed\n",
    "        for estim in self.estimators:\n",
    "            if self.use_already_fitted:\n",
    "                if not check_is_fitted(estim):\n",
    "                    estim.fit(X, y = y, sample_weight = sample_weight)\n",
    "                else:\n",
    "                    warn(f\"{estim} is already fitted and use_already_fitted was set to True in the constructor. The estimator won't be fitted, so ensure compatibility of inputs and outputs.\")\n",
    "            else:                \n",
    "                estim.fit(X, y = y, sample_weight = sample_weight)                                                                                                                                \n",
    "        \n",
    "        self.natural_weights_ = natural_weights\n",
    "        self.estimators_weights_ = weights        \n",
    "        self.output_dim_ = output_dim\n",
    "        \n",
    "        #fit one hot encoders of the nodes\n",
    "        terminal_nodes = super().apply(X, stack = False)\n",
    "        self.one_hot_node_embeddings_encoders_ = [OneHotEncoder().fit(xi) for xi in terminal_nodes]\n",
    "        #fit louvain embeddings\n",
    "        self.fit_embeddings(X, embedding_method = self.embedding_method,)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X, aggregate = True):\n",
    "        '''\n",
    "        predicts classes\n",
    "        '''\n",
    "        \n",
    "        weights = self.estimators_weights_\n",
    "        result = super()._iter_apply(method = 'predict', X = X)\n",
    "        sum_f = lambda a,b : weights[a]*result[a] + weights[b]*result[b]\n",
    "        \n",
    "        if aggregate:\n",
    "            result = reduce(sum_f, range(len(result)))\n",
    "        else:            \n",
    "            result = hstack([i.reshape(-1,1) for i in result])\n",
    "                \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MixedForestClassifier(MixedForestTransformer):            \n",
    "    \n",
    "    def fit(self, X, y = None, sample_weight = None):\n",
    "                \n",
    "        #check if multidim output\n",
    "        if len(y.shape) > 1:\n",
    "            output_dim = y.shape[-1]\n",
    "        else:\n",
    "            output_dim = 1\n",
    "            \n",
    "        if output_dim > 1:\n",
    "            multilabel = True\n",
    "        else:\n",
    "            multilabel = False\n",
    "            \n",
    "        #get \"natural\" weights of estimators\n",
    "        natural_weights = np.array([i.n_estimators for i in self.estimators])\n",
    "        natural_weights = natural_weights/natural_weights.sum()            \n",
    "        #set estimator weights\n",
    "        if self.estimators_weights is None:\n",
    "            weights = natural_weights            \n",
    "        else:\n",
    "            if len(self.estimators_weights) != len(self.estimators):\n",
    "                raise ValueError(f'Shape mismatch between estimators and weights ({len(self.estimators)} != {len(self.estimators_weights)})')            \n",
    "            weights = np.array(self.estimators_weights)\n",
    "            weights = weights/weights.sum()\n",
    "            \n",
    "        #fit estimators if needed\n",
    "        for estim in self.estimators:\n",
    "            if self.use_already_fitted:\n",
    "                if not check_is_fitted(estim):\n",
    "                    estim.fit(X, y = y, sample_weight = sample_weight)\n",
    "                else:\n",
    "                    warn(f\"{estim} is already fitted and use_already_fitted was set to True in the constructor. The estimator won't be fitted, so ensure compatibility of inputs and outputs.\")\n",
    "            else:                \n",
    "                estim.fit(X, y = y, sample_weight = sample_weight)\n",
    "                                \n",
    "        #check if classes are the same accross estimators\n",
    "        if self.fully_supervised:\n",
    "            classes = [estim.classes_ for estim in self.estimators]\n",
    "            \n",
    "            if multilabel:            \n",
    "                for i in range(len(classes)-1):\n",
    "                    for j in range(len(classes[i])):\n",
    "                        assert np.all(classes[i][j] == classes[i+1][j]), f'different classes in estimators: {classes[i]} and {classes[i+1]}'\n",
    "                classes = classes[0]\n",
    "\n",
    "            else:\n",
    "                for i in range(len(classes)-1):                \n",
    "                    assert np.all(classes[i] == classes[i+1]), f'different classes in estimators: {classes[i]} and {classes[i+1]}'\n",
    "                classes = classes[0]\n",
    "        else:\n",
    "            classes = None                                                                                        \n",
    "        \n",
    "        self.natural_weights_ = natural_weights\n",
    "        self.estimators_weights_ = weights\n",
    "        self.classes_ = classes\n",
    "        self.multilabel_ = multilabel\n",
    "        self.output_dim_ = output_dim\n",
    "        \n",
    "        #fit one hot encoders of the nodes\n",
    "        terminal_nodes = super().apply(X, stack = False)\n",
    "        self.one_hot_node_embeddings_encoders_ = [OneHotEncoder().fit(xi) for xi in terminal_nodes]\n",
    "        #fit louvain embeddings\n",
    "        self.fit_embeddings(X, embedding_method = self.embedding_method,)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        predicts classes\n",
    "        '''\n",
    "        if self.multilabel_:\n",
    "            probas = self.predict_proba(X)\n",
    "            labels = []\n",
    "            for i in range(len(probas)):\n",
    "                indices = np.argmax(probas[i], axis = 1)\n",
    "                labels.append(self.classes_[i][indices])\n",
    "            labels = np.array(labels).T\n",
    "        else:\n",
    "            probas = self.predict_proba(X)\n",
    "            indices = np.argmax(probas, axis = 1)\n",
    "            labels = self.classes_[indices]\n",
    "                \n",
    "        return labels\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        predicts proba of each class\n",
    "        '''\n",
    "        weights = self.estimators_weights_\n",
    "        result = self._iter_apply(method = 'predict_proba', X = X)\n",
    "        sum_f = lambda a,b : weights[a]*result[a] + weights[b]*result[b]\n",
    "        if self.multilabel_:\n",
    "            #reverse the order of arrays in list            \n",
    "            res = [[] for _ in range(self.output_dim_)]\n",
    "            for i in range(len(result)):                \n",
    "                for j in range(self.output_dim_):\n",
    "                    res[j].append(result[i][j])\n",
    "            \n",
    "            result = []\n",
    "            for dim_result in res:                \n",
    "                sum_f = lambda a,b : weights[a]*dim_result[a] + weights[b]*dim_result[b]\n",
    "                res_i = reduce(sum_f, range(len(dim_result)))                \n",
    "                result.append(res_i) \n",
    "        \n",
    "        else:            \n",
    "            result = reduce(sum_f, range(len(result)))\n",
    "        \n",
    "        return result                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
       "       dtype=int64),\n",
       " array([7985, 3132, 2929, 2746, 2758, 2611, 2514, 2446, 2408, 2211, 2126,\n",
       "        1696, 1785, 1649, 1510, 1577, 1541, 1534, 1440, 1466, 1397, 1378,\n",
       "        1266, 1170, 1113, 1054, 1092, 1095, 1018, 1063, 1086,  941,  958,\n",
       "         953,  902,  904,  885,  844,  848,  782,  815,  795,  760,  776,\n",
       "         735,  709,  671,  727,  702,  714,  641,  678,  711,  688,  676,\n",
       "         706,  696,  678,  656,  635,  648,  605,  620,  579,  615,  578,\n",
       "         575,  596,  514,  540,  546,  544,  534,  488,  506,  525,  543,\n",
       "         497,  493,  448,  428,  426,  411,  376,  366,  311,  349,  315,\n",
       "         354,  284,  275,  288,  269,  260,  296,  263,  249,  219,  209,\n",
       "          76], dtype=int64))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "mxfc = MixedForestRegressor(\n",
    "    [ExtraTreesClassifier(100, min_samples_leaf = 1,n_jobs = -1),RandomForestClassifier(100, min_samples_leaf = 10, n_jobs = -1)],\n",
    "    [1,10],\n",
    "    embedding_method='kmeans',\n",
    "    fully_supervised = False, \n",
    "    biadjecency_weights = 'weighted',\n",
    "    #resolution = 1,\n",
    "    n_clusters = 100\n",
    "    \n",
    ").fit(X,y)\n",
    "\n",
    "\n",
    "embeddings = mxfc.transform(X).A\n",
    "clusters = np.argmax(embeddings, 1)\n",
    "\n",
    "#sns.scatterplot(X[:,0], X[:,1], hue = clusters, palette = 'tab20')\n",
    "#sns.scatterplot(X[:,1], X[:,2], hue = embeddings.max(1) <.5)\n",
    "\n",
    "np.unique(clusters, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cluster'] = clusters\n",
    "#df['max_proba'] = embeddings.max(1)\n",
    "#px.scatter_3d(df, 'X0', 'X1', 'X2', color = 'y', symbol = 'cluster', size = 'max_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning:\n",
      "\n",
      "`distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning:\n",
      "\n",
      "`distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning:\n",
      "\n",
      "`distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(mxfc.transform(X, alpha = .25).max(1).data)\n",
    "sns.distplot(mxfc.transform(X, alpha = .5).max(1).data)\n",
    "sns.distplot(mxfc.transform(X, alpha = 1).max(1).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning:\n",
      "\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.661074660164821, 8.746979463337267)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "entropies = []\n",
    "sizes = []\n",
    "proportion_class = []\n",
    "for c in np.unique(clusters):\n",
    "    msk = clusters == c\n",
    "    entropies.append(entropy(y[msk]))\n",
    "    sizes.append(msk.sum())\n",
    "    proportion_class.append(pd.Series(y[msk]).value_counts(1).max())\n",
    "\n",
    "#jnt = sns.jointplot(sizes, entropies)\n",
    "jnt = sns.jointplot(sizes, proportion_class)\n",
    "jnt.ax_joint.set_xlabel('Cluster size')\n",
    "jnt.ax_joint.set_ylabel('Cluster Max Purity')\n",
    "np.array(entropies).mean(),entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], dtype=int64),\n",
       " array([949, 793, 741, 712, 571, 568, 472, 429, 360, 349, 319, 307, 308,\n",
       "        297, 242, 256, 233, 229, 224, 211, 182, 185, 168, 155, 151, 142,\n",
       "        124, 127, 112,  84], dtype=int64))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpt = ForestBipartiteGraphTransformer(\n",
    "    RandomForestClassifier(400, min_samples_leaf = 1),\n",
    "    embedding_method='kmeans',\n",
    "    n_clusters = 30,\n",
    ").fit(X,y)\n",
    "\n",
    "\n",
    "embeddings = bpt.transform(X).A\n",
    "clusters = np.argmax(embeddings, 1)\n",
    "\n",
    "#sns.scatterplot(X[:,0], X[:,1], hue = clusters, palette = 'tab20')\n",
    "#sns.scatterplot(X[:,1], X[:,2], hue = embeddings.max(1) <.5)\n",
    "\n",
    "np.unique(clusters, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning:\n",
      "\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.879106388175367, 8.746979463337267)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "entropies = []\n",
    "sizes = []\n",
    "proportion_class = []\n",
    "for c in np.unique(clusters):\n",
    "    msk = clusters == c\n",
    "    entropies.append(entropy(y[msk]))\n",
    "    sizes.append(msk.sum())\n",
    "    proportion_class.append(pd.Series(y[msk]).value_counts(1).max())\n",
    "\n",
    "#jnt = sns.jointplot(sizes, entropies)\n",
    "jnt = sns.jointplot(sizes, proportion_class)\n",
    "jnt.ax_joint.set_xlabel('Cluster size')\n",
    "jnt.ax_joint.set_ylabel('Cluster Max Purity')\n",
    "np.array(entropies).mean(),entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_76.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['cluster'] = clusters\n",
    "df['max_proba'] = embeddings.max(1)\n",
    "px.scatter_3d(df, 'X0', 'X1', 'X2', color = 'y', symbol = 'cluster', size = 'max_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.04897401256034, 8.74800360330211)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48061"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class EstimatorKernel(BaseEstimator, TransformerMixin):    \n",
    "    '''\n",
    "    creates a kernel with some specified estimator.\n",
    "    projection method will be performed according to projection_method.\n",
    "    projection method can be a string refering to estimators method used to project,\n",
    "    or a callable, that receives the estimator and X (vector to be projected) as the inputs.\n",
    "    should return the projections of X according to estimator.\n",
    "    norm will normalize vectors in matrices prior to applying dot products.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator:BaseEstimator,\n",
    "        projection_method:Union[str,callable],\n",
    "        nearest_neighbors_estimator,\n",
    "        fit_neighbors_index:bool = True,\n",
    "        n_neighbors:int = 30\n",
    "    ):\n",
    "        '''\n",
    "        creates a kernel with some specified estimator.\n",
    "        projection method will be performed according to projection_method.\n",
    "        projection method can be a string refering to estimators method used to project,\n",
    "        or a callable, that receives the estimator and X (vector to be projected) as the inputs.\n",
    "        should return the projections of X according to estimator.\n",
    "        norm will normalize vectors in matrices prior to applying dot products.\n",
    "        '''\n",
    "        self.estimator = estimator\n",
    "        self.projection_method = projection_method\n",
    "        self.nearest_neighbors_estimator = nearest_neighbors_estimator\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.fit_neighbors_index = fit_neighbors_index\n",
    "        \n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        '''\n",
    "        Allows accessing self.estimator attributes if not found in first object level\n",
    "        '''\n",
    "        return getattr(self.estimator, attr)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        projects X into new space, according to projection_method\n",
    "        '''        \n",
    "                        \n",
    "        if callable(self.projection_method):\n",
    "            return self.projection_method(self.estimator, X)\n",
    "        else:\n",
    "            return getattr(self.estimator, self.projection_method)(X)\n",
    "    \n",
    "    def fit(self, X, y = None, save_values = None, **kwargs):\n",
    "        '''\n",
    "        X is the feature space,\n",
    "        y is used only for supervised Kernels\n",
    "        save_values are values associated with each \"Embeding\". During transform,\n",
    "        the values of saved_values are retrieved according to indexes returned by Nearest Neighbor query        \n",
    "        '''\n",
    "        if not save_values is None:\n",
    "            if not len(save_values) == len(X):\n",
    "                raise IndexError(f'X and save_values must have the same shape along the first dimension. Got {X.shape} and {save_values.shape}')\n",
    "        \n",
    "        self.estimator.fit(X, y, **kwargs)\n",
    "        \n",
    "        if self.fit_neighbors_index:\n",
    "            #make space transformation\n",
    "            train_projection_space_ = self.transform(X) #saves projection space of X in train\n",
    "\n",
    "            if save_values is None:            \n",
    "                save_values = np.empty((X.shape[0], 0)) #empty array        \n",
    "\n",
    "            #fit index\n",
    "            self.nearest_neighbors_estimator.fit(train_projection_space_)\n",
    "\n",
    "            #save states\n",
    "            #self.train_projection_space_ = train_projection_space_ #is it really necessary to save this? possibly yieds memory overhead\n",
    "            self.train_projection_values_ = save_values\n",
    "        \n",
    "        return self\n",
    "                \n",
    "            \n",
    "    def kneighbors(self, X = None, n_neighbors = None, return_distance = True):\n",
    "        '''\n",
    "        runs nearest neighbor search in the transformed space index\n",
    "        '''        \n",
    "                    \n",
    "        if not self.fit_neighbors_index:\n",
    "            raise AttributeError('This method is only available when fit_neighbors_index is set to True in the constructor')\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            n_neighbors = self.n_neighbors\n",
    "            \n",
    "        #make space transformation\n",
    "        X = self.transform(X)\n",
    "        #query in index\n",
    "        result = self.nearest_neighbors_estimator.kneighbors(X, n_neighbors = n_neighbors, return_distance = return_distance)\n",
    "                \n",
    "        return result #dist, idxs\n",
    "    \n",
    "    def kneighbors_graph(self, X = None, n_neighbors = None, mode = 'similarity'):\n",
    "        \n",
    "        if not self.fit_neighbors_index:\n",
    "            raise AttributeError('This method is only available when fit_neighbors_index is set to True in the constructor')\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            n_neighbors = self.n_neighbors\n",
    "            \n",
    "        #make space transformation\n",
    "        if not X is None:\n",
    "            X = self.transform(X)\n",
    "        #query in index\n",
    "        graph = self.nearest_neighbors_estimator.kneighbors_graph(X, n_neighbors = n_neighbors, mode = mode)\n",
    "        return graph\n",
    "        \n",
    "    def query(self, X = None, n_neighbors = None):\n",
    "        '''\n",
    "        same as kneighbors, but instead of returning indexes, returns values in self.train_projection_values_\n",
    "        '''\n",
    "        if not self.fit_neighbors_index:\n",
    "            raise AttributeError('This method is only available when fit_neighbors_index is set to True in the constructor')\n",
    "            \n",
    "        dist, idxs = self.kneighbors(X, n_neighbors, return_distance = True)\n",
    "        \n",
    "        if hasattr(self.train_projection_values_, 'iloc'):\n",
    "            values = [self.train_projection_values_.iloc[idx] for idx in idxs]        \n",
    "        \n",
    "        else:\n",
    "            values = [self.train_projection_values_[idx] for idx in idxs]\n",
    "        \n",
    "        return values, dist\n",
    "    \n",
    "    def update_space(self, X, save_values = None):\n",
    "        '''\n",
    "        updates self.train_projection_space_ and self.train_projection_values_ with new data.\n",
    "        new values are found running self.transform on X\n",
    "        '''\n",
    "        if not self.fit_neighbors_index:\n",
    "            raise AttributeError('This method is only available when fit_neighbors_index is set to True in the constructor')\n",
    "        \n",
    "        X = self.transform(X)\n",
    "        \n",
    "        self.train_projection_space_ = vstack([self.train_projection_space_, X])\n",
    "        \n",
    "        if save_values is None:            \n",
    "            save_values = np.empty((X.shape[0], self.train_projection_values_.shape[-1])) #empty array\n",
    "            \n",
    "        \n",
    "        #refit knn index\n",
    "        self.nearest_neighbors_estimator.fit(self.train_projection_space_)\n",
    "        \n",
    "        self.train_projection_values_ = vstack([self.train_projection_values_, save_values])        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JaccardForestKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class JaccardForestKernel(EstimatorKernel):\n",
    "    '''\n",
    "    A Space tranformation performed based on Forest transformations.\n",
    "    Can be supervised or not (CARTs, RandomTreeEmbeddings, Boosted trees...)\n",
    "    \n",
    "    the embedding_space is sparse and can be defined as the `decision_path` space or `terminal_nodes`\n",
    "    space.\n",
    "    '''             \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator:BaseEstimator,\n",
    "        n_neighbors:int = 30,\n",
    "        fit_neighbors_index:bool = True,\n",
    "        index_time_params:dict={'M': 30, 'indexThreadQty': 4, 'efConstruction': 100, 'post': 0},\n",
    "        query_time_params:dict={'efSearch': 100},\n",
    "        verbose:bool = False\n",
    "    ):\n",
    "        \n",
    "        #save init params for sklearn consistency\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.index_time_params=index_time_params\n",
    "        self.query_time_params=query_time_params\n",
    "        self.verbose=verbose\n",
    "        self.fit_neighbors_index=fit_neighbors_index\n",
    "        \n",
    "        #instantiate jacard distance nearest neighbor index\n",
    "        nn_obj = FastJaccardNN(\n",
    "            n_neighbors = n_neighbors,\n",
    "            index_time_params=index_time_params,\n",
    "            query_time_params=query_time_params,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "                        \n",
    "        super().__init__(\n",
    "            estimator = estimator,\n",
    "            projection_method=None,\n",
    "            nearest_neighbors_estimator=nn_obj,\n",
    "            fit_neighbors_index=fit_neighbors_index,\n",
    "            n_neighbors=n_neighbors            \n",
    "        )        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = self.estimator.apply(X)\n",
    "        #handle boosting case\n",
    "        if len(X.shape) > 2:\n",
    "            X = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "            \n",
    "        if hasattr(self, 'one_hot_node_embeddings_encoder_'):            \n",
    "            X = self.one_hot_node_embeddings_encoder_.transform(X)\n",
    "\n",
    "        else:            \n",
    "            self.one_hot_node_embeddings_encoder_ = OneHotEncoder().fit(X)\n",
    "            X = self.one_hot_node_embeddings_encoder_.transform(X)\n",
    "                            \n",
    "        return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953235"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings < .1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dgp\n",
    "\n",
    "X,y = make_bimodal_assymetric_regression(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaccardForestKernel(estimator=RandomForestRegressor())"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "fkernel = JaccardForestKernel(RandomForestRegressor())\n",
    "fkernel.fit(X, y, save_values = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkernel.query(X[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CategoricalLinearKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoricalLinearKernel(EstimatorKernel):    \n",
    "    '''\n",
    "    Linear model kernel recommended for high cardinality one hot encoded categorical variables.\n",
    "    kernel space is defined by liner model coefficients indexed by the nonzero elements\n",
    "    of X\n",
    "    \n",
    "    If encode is set to true, a customized onehotencoder will encode the categorical input.\n",
    "    \n",
    "    This kernel will only work if the output of the one hot encoded vectors  have always the same number\n",
    "    of nonzero elements (equal to the number of categorical features). Thus, its recomended to use the default\n",
    "    encoder, because it asserts this condition is met during one hot encoding\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        n_neighbors=30,\n",
    "        fit_neighbors_index = True,\n",
    "        encode = False,\n",
    "        n_components = None,\n",
    "        index_time_params={'M': 30, 'indexThreadQty': 8, 'efConstruction': 100, 'post': 0},\n",
    "        query_time_params={'efSearch': 100},\n",
    "        verbose=False,\n",
    "        **pcakwargs\n",
    "    ):\n",
    "        \n",
    "        self.encode = encode\n",
    "        self.n_components = n_components\n",
    "        self.pcakwargs = pcakwargs\n",
    "        self.estimator = estimator\n",
    "                \n",
    "        #save init params for sklearn consistency\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.index_time_params=index_time_params\n",
    "        self.query_time_params=query_time_params\n",
    "        self.verbose=verbose\n",
    "        self.fit_neighbors_index=fit_neighbors_index\n",
    "        \n",
    "        #instantiate jacard distance nearest neighbor index\n",
    "        nn_obj = FastL2NN(\n",
    "            n_neighbors = n_neighbors,\n",
    "            index_time_params=index_time_params,\n",
    "            query_time_params=query_time_params,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "                        \n",
    "        super().__init__(\n",
    "            estimator = estimator,\n",
    "            projection_method=None,\n",
    "            nearest_neighbors_estimator=nn_obj,\n",
    "            fit_neighbors_index=fit_neighbors_index,\n",
    "            n_neighbors=n_neighbors            \n",
    "        )        \n",
    "                \n",
    "        return    \n",
    "    \n",
    "    def fit(self, X, y = None, save_values = None, **kwargs):\n",
    "        \n",
    "        if self.encode:            \n",
    "            if not self.n_components is None:\n",
    "                self.estimator = make_pipeline(RobustEncoder(), self.estiamtor, PCA(self.n_components, **self.pcakwargs))\n",
    "            else:\n",
    "                self.estimator = make_pipeline(RobustEncoder(), self.estimator)\n",
    "        else:\n",
    "            if not self.n_components is None:\n",
    "                self.estimator = make_pipeline(self.estiamtor, PCA(self.n_components, **self.pcakwargs))\n",
    "            else:\n",
    "                pass\n",
    "                                \n",
    "        return super().fit(X, y, save_values, **kwargs)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        multiplies sparse vector to its coef_ s from linear model.\n",
    "        if multiclass classification, the number of final features will be\n",
    "        n*original_n_features_before_one_hot_encoding\n",
    "        '''\n",
    "        \n",
    "        if self.encode:\n",
    "            coefs = self.estimator[-1].coef_\n",
    "            X = self.estimator[0].transform(X)\n",
    "        else:            \n",
    "            coefs = self.estimator.coef_\n",
    "        \n",
    "        #create attr if it does now exist yet:\n",
    "        #this line is supposed to run only during fit call\n",
    "        if not hasattr(self,'dim_embeddings_'):\n",
    "            self.dim_embeddings_ = len(X[0].data)\n",
    "                \n",
    "        if len(coefs.shape) == 1:\n",
    "            coefs = coefs.reshape(1,-1)\n",
    "        \n",
    "        embeddings = []\n",
    "        for dim in range(coefs.shape[0]):\n",
    "            #assumes all rows have the same ammount of nonzero elements\n",
    "            dim_embeddings = coefs[dim, X.nonzero()[1]].reshape(X.shape[0], self.dim_embeddings_)\n",
    "            embeddings.append(dim_embeddings)                    \n",
    "                \n",
    "        return hstack(embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "\n",
    "X_cat = np.random.randint(0,10, size = (10_000, 100)).astype(str)\n",
    "y_reg = np.random.randn(10_000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CategoricalLinearKernel(encode=True,\n",
       "                        estimator=Pipeline(steps=[('robustencoder',\n",
       "                                                   RobustEncoder()),\n",
       "                                                  ('sgdregressor',\n",
       "                                                   SGDRegressor())]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_kernel = CategoricalLinearKernel(SGDRegressor(), encode = True)\n",
    "cat_kernel.fit(X_cat, y_reg, save_values = y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.75131392],\n",
       "         [ 0.14790968],\n",
       "         [-0.72471629],\n",
       "         [-1.4413358 ],\n",
       "         [ 0.03990467],\n",
       "         [ 0.10910946],\n",
       "         [ 1.5351463 ],\n",
       "         [ 0.54819518],\n",
       "         [ 0.368883  ],\n",
       "         [-0.49814587],\n",
       "         [ 0.55611049],\n",
       "         [-1.93758336],\n",
       "         [ 0.82971074],\n",
       "         [-0.11549446],\n",
       "         [-0.39815426],\n",
       "         [-0.0313381 ],\n",
       "         [ 0.3689665 ],\n",
       "         [-0.04878705],\n",
       "         [ 0.08720136],\n",
       "         [ 0.8904295 ],\n",
       "         [-0.58962797],\n",
       "         [-1.08723441],\n",
       "         [ 3.12410873],\n",
       "         [-0.06718426],\n",
       "         [ 1.03804078],\n",
       "         [ 0.70854673],\n",
       "         [-0.43204652],\n",
       "         [ 0.54480574],\n",
       "         [ 0.03619711],\n",
       "         [ 0.4013929 ]]),\n",
       "  array([[-0.51501537],\n",
       "         [ 0.57677978],\n",
       "         [ 0.8394021 ],\n",
       "         [-0.77986324],\n",
       "         [ 0.50513874],\n",
       "         [-0.67342598],\n",
       "         [ 0.96447019],\n",
       "         [ 0.4542087 ],\n",
       "         [ 0.65358693],\n",
       "         [-1.91023683],\n",
       "         [-0.05376845],\n",
       "         [-0.14586024],\n",
       "         [ 0.56073119],\n",
       "         [ 0.41880327],\n",
       "         [ 0.35954433],\n",
       "         [ 0.26760767],\n",
       "         [-1.22060981],\n",
       "         [-1.64104426],\n",
       "         [ 0.17189515],\n",
       "         [ 0.51605029],\n",
       "         [-0.12787924],\n",
       "         [ 0.81138588],\n",
       "         [ 1.74776501],\n",
       "         [ 0.29278236],\n",
       "         [ 0.22974481],\n",
       "         [-0.04474925],\n",
       "         [ 0.47053995],\n",
       "         [ 0.76604324],\n",
       "         [-0.34412338],\n",
       "         [-3.17261482]])],\n",
       " [array([0.        , 0.12450964, 0.12909028, 0.13170478, 0.1341726 ,\n",
       "         0.13763055, 0.1377786 , 0.1388303 , 0.13966076, 0.13984495,\n",
       "         0.1399003 , 0.1407754 , 0.14091651, 0.14217936, 0.14311126,\n",
       "         0.14333132, 0.14352784, 0.14376411, 0.14405411, 0.14514884,\n",
       "         0.14546655, 0.14703882, 0.14704357, 0.14738512, 0.14739732,\n",
       "         0.14759833, 0.14773975, 0.14828928, 0.14851174, 0.14866754],\n",
       "        dtype=float32),\n",
       "  array([0.        , 0.11292889, 0.1295458 , 0.13166863, 0.13192987,\n",
       "         0.13492726, 0.13553558, 0.13968213, 0.1401993 , 0.1409548 ,\n",
       "         0.14132653, 0.14145726, 0.14148706, 0.14159623, 0.14332494,\n",
       "         0.14416511, 0.14433897, 0.14542165, 0.14625773, 0.14640817,\n",
       "         0.14644612, 0.14649718, 0.14675276, 0.14678285, 0.14688998,\n",
       "         0.14695585, 0.14707205, 0.14726777, 0.14785433, 0.14798608],\n",
       "        dtype=float32)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_kernel.query(X_cat[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearBottleneckKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClassificationLinearBottleneck(MLPClassifier):\n",
    "    '''\n",
    "    Linear boottleneck of a classification task, usefull for dimensionality reduction\n",
    "    or densification of sparse representations.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components = 2,        \n",
    "        solver='adam',\n",
    "        alpha=0.0001,\n",
    "        batch_size='auto',\n",
    "        learning_rate='constant',\n",
    "        learning_rate_init=0.001,\n",
    "        power_t=0.5,\n",
    "        max_iter=200,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        tol=0.0001,\n",
    "        verbose=False,\n",
    "        warm_start=False,\n",
    "        momentum=0.9,\n",
    "        nesterovs_momentum=True,\n",
    "        early_stopping=False,\n",
    "        validation_fraction=0.1,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-08,\n",
    "        n_iter_no_change=10,\n",
    "        max_fun=15000,\n",
    "    ):\n",
    "        \n",
    "        #set attributes, some will be overriden in super().__init__ call        \n",
    "        self.solver = solver\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.power_t = power_t\n",
    "        self.max_iter = max_iter\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.warm_start = warm_start\n",
    "        self.momentum = momentum\n",
    "        self.nesterovs_momentum = nesterovs_momentum\n",
    "        self.early_stopping = early_stopping\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.n_iter_no_change = n_iter_no_change\n",
    "        self.max_fun = max_fun\n",
    "                        \n",
    "        super().__init__(hidden_layer_sizes = (n_components,), activation = 'identity', **self.__dict__)\n",
    "        self.n_components = n_components\n",
    "        return\n",
    "    \n",
    "    def transform(self, X, **kwargs):\n",
    "        '''\n",
    "        projects inputs to have size (n_samples, n_components)\n",
    "        '''        \n",
    "        return _get_sklearn_mlp_activations(self, X)\n",
    "        \n",
    "\n",
    "class RegressionLinearBottleneck(MLPRegressor):\n",
    "    '''\n",
    "    Linear boottleneck of a classification task, usefull for dimensionality reduction\n",
    "    or densification of sparse representations.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components = 2,        \n",
    "        solver='adam',\n",
    "        alpha=0.0001,\n",
    "        batch_size='auto',\n",
    "        learning_rate='constant',\n",
    "        learning_rate_init=0.001,\n",
    "        power_t=0.5,\n",
    "        max_iter=200,\n",
    "        shuffle=True,\n",
    "        random_state=None,\n",
    "        tol=0.0001,\n",
    "        verbose=False,\n",
    "        warm_start=False,\n",
    "        momentum=0.9,\n",
    "        nesterovs_momentum=True,\n",
    "        early_stopping=False,\n",
    "        validation_fraction=0.1,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-08,\n",
    "        n_iter_no_change=10,\n",
    "        max_fun=15000,\n",
    "    ):\n",
    "        \n",
    "        #set attributes, some will be overriden in super().__init__ call        \n",
    "        self.solver = solver\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.power_t = power_t\n",
    "        self.max_iter = max_iter\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.warm_start = warm_start\n",
    "        self.momentum = momentum\n",
    "        self.nesterovs_momentum = nesterovs_momentum\n",
    "        self.early_stopping = early_stopping\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.n_iter_no_change = n_iter_no_change\n",
    "        self.max_fun = max_fun\n",
    "                        \n",
    "        super().__init__(hidden_layer_sizes = (n_components,), activation = 'identity', **self.__dict__)\n",
    "        self.n_components = n_components\n",
    "        return\n",
    "    \n",
    "    def transform(self, X, **kwargs):\n",
    "        '''\n",
    "        projects inputs to have size (n_samples, n_components)\n",
    "        '''        \n",
    "        return _get_sklearn_mlp_activations(self, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_sklearn_mlp_activations(self, X, output_layer = -2):\n",
    "    hidden_layer_sizes = self.hidden_layer_sizes\n",
    "    if not hasattr(hidden_layer_sizes, \"__iter__\"):\n",
    "        hidden_layer_sizes = [hidden_layer_sizes]\n",
    "    hidden_layer_sizes = list(hidden_layer_sizes)\n",
    "    layer_units = [X.shape[1]] + hidden_layer_sizes + \\\n",
    "        [self.n_outputs_]\n",
    "    activations = [X]\n",
    "    for i in range(self.n_layers_ - 1):\n",
    "        activations.append(np.empty((X.shape[0],\n",
    "                                     layer_units[i + 1])))\n",
    "    self._forward_pass(activations)\n",
    "    return activations[output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MLPKernel(EstimatorKernel):\n",
    "    \n",
    "    '''\n",
    "    returns the output of last hidden layer (before softmax/linear layer)\n",
    "    as space projection.\n",
    "    \n",
    "    Recomended for dimensionality reduction and Context specific bag of words task\n",
    "    '''    \n",
    "    def __init__(self, estimator, output_layer = -2, norm='l2'):\n",
    "        \n",
    "        self.projection_method = partial(_get_sklearn_mlp_activations, output_layer = output_layer)\n",
    "        self.estimator = estimator\n",
    "        self.output_layer = output_layer\n",
    "        self.norm = norm\n",
    "        return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BOWKernel(MLPKernel):\n",
    "    '''\n",
    "    `MLPKernel` Alias, intended for Bag Of Words application.\n",
    "    Generates supervised embeddings (context specific embeddings)\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DiscretizedTargetKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBinsDiscretizer()\n",
    "class DiscretizedTargetTransformer(BaseEstimator):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        n_bins=5,\n",
    "        encode='ordinal',\n",
    "        strategy='kmeans',\n",
    "        dtype=None,   \n",
    "    ):\n",
    "        '''\n",
    "        Fits a supervised \n",
    "        '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EstimatorKernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\USERAM~1\\AppData\\Local\\Temp/ipykernel_6704/1937611074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDiscretizedTargetKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEstimatorKernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     def __init__(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EstimatorKernel' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "class DiscretizedTargetKernel(EstimatorKernel):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        n_bins=10,\n",
    "        encode='ordinal',\n",
    "        strategy='kmeans',        \n",
    "        n_neighbors=30,\n",
    "        fit_neighbors_index = True,\n",
    "        index_time_params={'indexThreadQty': 8, 'efConstruction': 100},\n",
    "        query_time_params={'efSearch': 100},\n",
    "        verbose=False,            \n",
    "    ):\n",
    "        \n",
    "                \n",
    "        #save init params for sklearn consistency\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.index_time_params=index_time_params\n",
    "        self.query_time_params=query_time_params\n",
    "        self.verbose=verbose\n",
    "        self.fit_neighbors_index=fit_neighbors_index\n",
    "        self.n_bins=n_bins\n",
    "        self.encode=encode\n",
    "        self.strategy=strategy\n",
    "        \n",
    "        #instantiate KL Divergence nearest neighbor index\n",
    "        nn_obj = FastKLDivNN(\n",
    "            n_neighbors = n_neighbors,\n",
    "            index_time_params=index_time_params,\n",
    "            query_time_params=query_time_params,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "                        \n",
    "        super().__init__(\n",
    "            estimator = estimator,\n",
    "            projection_method='predict_proba',\n",
    "            nearest_neighbors_estimator=nn_obj,\n",
    "            fit_neighbors_index=fit_neighbors_index,\n",
    "            n_neighbors=n_neighbors            \n",
    "        )        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y = None, save_values = None, **kwargs):\n",
    "        \n",
    "        discretizer = KBinsDiscretizer(\n",
    "            n_bins = self.n_bins,\n",
    "            encode = self.encode,\n",
    "            strategy = self.strategy,            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        y = discretizer.fit_transform(y)\n",
    "        \n",
    "        self.discretizer = discretizer                                \n",
    "        return super().fit(X, y, save_values, **kwargs)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = self.estimator.predict_proba(X)\n",
    "        #handle multiclass (multi dimensional joint dist)\n",
    "        if isinstance(X, list):\n",
    "            X = hstack(X)\n",
    "        return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DiscretizedTargetKernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\USERAM~1\\AppData\\Local\\Temp/ipykernel_6704/2070703300.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_bimodal_assymetric_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10_000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdiscrete_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDiscretizedTargetKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'kmeans'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdiscrete_kernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DiscretizedTargetKernel' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X, y = make_bimodal_assymetric_regression(10_000)\n",
    "\n",
    "discrete_kernel = DiscretizedTargetKernel(RandomForestClassifier(), n_bins = 30, n_neighbors = 100,  strategy = 'kmeans')\n",
    "\n",
    "discrete_kernel.fit(X, y, save_values = y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user ambev\\desktop\\mypackages\\heartwood\\venv\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2bafad66a08>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.choice(len(X))\n",
    "\n",
    "plot = sns.jointplot(*discrete_kernel.query(X[idx:idx+1])[0][0].T)\n",
    "plot.ax_joint.scatter(*y[idx], color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted cluster.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kernel.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
